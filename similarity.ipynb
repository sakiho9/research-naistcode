{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 類似度スコア算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "w2v_model =  models.KeyedVectors.load_word2vec_format('jawiki.word_vectors.200d.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score = 0.9893434047698975\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# fugashiのインストール\n",
    "%pip install fugashi\n",
    "# gensimのインストール\n",
    "%pip install gensim\n",
    "\n",
    "# gensimのKeyedVectorsで使用されているword2vecモデルをダウンロード\n",
    "# jawikiの200次元のword2vecモデル\n",
    "wget https://github.com/singletongue/WikiEntVec/releases/download/20190520/jawiki.word_vectors.200d.txt.bz2\n",
    "bunzip2 jawiki.word_vectors.200d.txt.bz2\n",
    "\n",
    "# MeCabとipadicの辞書のインストール\n",
    "# MeCabのインストール（Linuxの場合）\n",
    "%sudo apt-get update\n",
    "%sudo apt-get install mecab\n",
    "%sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8\n",
    "# MeCabのインストール（macOSの場合、Homebrewを使用）\n",
    "%brew install mecab\n",
    "%brew install mecab mecab-ipadic\n",
    "\n",
    "# numpyのインストール\n",
    "%pip install numpy\n",
    "'''\n",
    "\n",
    "import ipadic\n",
    "from fugashi import GenericTagger\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "fugger = GenericTagger(ipadic.MECAB_ARGS)\n",
    "\n",
    "# from gensim import models\n",
    "# w2v_model =  models.KeyedVectors.load_word2vec_format('jawiki.word_vectors.200d.txt', binary=False)\n",
    "\n",
    "def get_sim(s1, s2):\n",
    "    sentence1 = [w.surface for w in fugger(s1)]\n",
    "    sentence2 = [w.surface for w in fugger(s2)]\n",
    "    if len(sentence1) > 0:\n",
    "        for word in sentence1:\n",
    "            if word == sentence1[0]:\n",
    "                sentence_vec1 = w2v_model.__getitem__(word)\n",
    "            else:\n",
    "                sentence_vec1 = sentence_vec1 + w2v_model.__getitem__(word)\n",
    "        sentence_vec1 = sentence_vec1 / len(sentence1)\n",
    "    if len(sentence2) > 0:\n",
    "        for word in sentence2:\n",
    "            if word == sentence2[0]:\n",
    "                sentence_vec2 = w2v_model.__getitem__(word)\n",
    "            else:\n",
    "                sentence_vec2 = sentence_vec2 + w2v_model.__getitem__(word)\n",
    "        sentence_vec2 = sentence_vec2 / len(sentence2)\n",
    "    print(f'Similarity Score = {dot(sentence_vec1, sentence_vec2)/(norm(sentence_vec1)*norm(sentence_vec2))}')\n",
    "\n",
    "get_sim(\"エピソード１\",\"エピソード２\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipadic\n",
    "from fugashi import GenericTagger\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "fugger = GenericTagger(ipadic.MECAB_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "比較したいエピソード: Episode 10\n",
      "Episode: 生理期間中によそのお宅を訪問する予定が重なった時、その家のお手洗いを借りた時に生理用品を交換したくても、使用後の生理用品の対処が分かりません。みなさんどのようにされているのでしょうか？よその家に使用後のものを捨てさせてもらうのは恥ずかしいし申し訳なくてできません。かといってバッグに入れて持ち帰るのも、衛生的でない気がして躊躇してしまいます。なるべく、そのお宅に入る前後で交換して、お宅にいる間は交換しなくていいようにしていますが、泊まる予定だと長時間交換しないわけにもいきません。生理と訪問/宿泊が重ならないようにカレンダーとにらめっこをして予定を組みますが、予定外だとどうしようもありません。よそのお宅に行くときに生理が重なった時、他の人がどのようにしているのか知りたいです…！\n",
      "上位3つの類似エピソード\n",
      "Episode 7: Similarity Score = 0.9848636984825134\n",
      "普段の家事分担の中で、買い物を担当することが多いです。ある日、パートナーから「おりものシートもついでにお願いしてもいい？」と何だか申し訳なさそうにお願いされました。売り場に入りにくいからでしょうか？それとも、どこかタブーのように感じてしまっているのでしょうか？私から理由を聞くのもはばかられたので、「全然いいよ！」と返すにとどまったのですが、、、。パートナーはどのような心理だったのでしょうか？？また、皆さんはこういった場面でどのように対応されているのでしょうか？？\n",
      "Episode 23: Similarity Score = 0.9828354716300964\n",
      "大学生のころ、友だちの家に遊びに行ったときに急に生理が始まった時、「いろいろあるよ！どれにする？！」とニコニコしながら大きな箱からたくさんの生理用品を出して種類とかについて説明してくれた時は、変に気後れしなくてよくなって、すごくうれしかったなぁと記憶に残ってます。\n",
      "Episode 37: Similarity Score = 0.9822352528572083\n",
      "メンタル的に多分、30代半ばから参ってはいたと、振り返れば思います。四季折々、いろいろな仲間とアウトドアや旅行や企画のない週末は無かったり、楽しさとワクワクを求めて元気いっぱい過ごしてはいましたが、今考えてみると、無理があったんだと思います。年に一回は4～5日の一人旅をしてリセットをかけないと自分の中にたまった何かでポジティブさや優しさがすり減ってしまうと感じていました。一人旅から戻ると、また楽しく過ごせるんです。職場が変わり、出会いがあり結婚に出産にと生活が激変する中で、思うようにリセットもかけられず、何度か鬱状態を体験し、そう認めてあげなかったツケを体を壊すという形で受け止めることになりました。数年がたち、その治療の過程で、更年期障害に直面しました。治療の過程で女性外来とそこで診療してくださる有名な先生に出会いました。治療を始めて、一番顕著だったことは、世界がクリアに見えたこと。自分が地面ばかりを見つめて歩いていたと、出勤途中の道すがら分かったことです。知らず知らずのうちにうつむいて歩いていたんだと。CMなどでは聞いていた更年期障害。いろいろな症状がありますが、私はホルモン補充療法を行いましたが、そのおかげでこんなに心が晴れやかになるなんて、舐めてたなぁと思います。周りに、心身不調な女性が居たら、受診を勧めます。男性でもやはり勧めます。せわしない世の中で心は疲弊しがちで、良くないスパイラルにストップが掛けられれば、本人にも家族にも良いことだと思います。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_sim2(s1, s2):\n",
    "    sentence1 = [w.surface for w in fugger(s1) if w.surface in w2v_model]\n",
    "    sentence2 = [w.surface for w in fugger(s2) if w.surface in w2v_model]\n",
    "    if len(sentence1) > 0:\n",
    "        for word in sentence1:\n",
    "            if word == sentence1[0]:\n",
    "                sentence_vec1 = w2v_model.__getitem__(word)\n",
    "            else:\n",
    "                sentence_vec1 = sentence_vec1 + w2v_model.__getitem__(word)\n",
    "        sentence_vec1 = sentence_vec1 / len(sentence1)\n",
    "    if len(sentence2) > 0:\n",
    "        for word in sentence2:\n",
    "            if word == sentence2[0]:\n",
    "                sentence_vec2 = w2v_model.__getitem__(word)\n",
    "            else:\n",
    "                sentence_vec2 = sentence_vec2 + w2v_model.__getitem__(word)\n",
    "        sentence_vec2 = sentence_vec2 / len(sentence2)\n",
    "    similarity = dot(sentence_vec1, sentence_vec2)/(norm(sentence_vec1)*norm(sentence_vec2))\n",
    "    return similarity\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('data/logepisode.csv')\n",
    "df['エピソード本文'] = df['エピソード本文'].str.replace('\\r', '').str.replace('\\n', '')\n",
    "\n",
    "x = 10 # 比較したいエピソード番号\n",
    "print(f'比較したいエピソード: Episode {x}')\n",
    "print(f'Episode: {df['エピソード本文'][x]}')\n",
    "print('上位3つの類似エピソード')\n",
    "similarity_scores = []\n",
    "for i in range(1, len(df['エピソード本文'])):\n",
    "    if i != x:\n",
    "        similarity = get_sim2(df['エピソード本文'][x], df['エピソード本文'][i])\n",
    "        similarity_scores.append((i, similarity))\n",
    "\n",
    "# Sort the similarity scores in descending order\n",
    "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the top 3 episodes\n",
    "top_3_episodes = similarity_scores[:3]\n",
    "# print(top_3_episodes)\n",
    "\n",
    "# Print the top 3 episodes\n",
    "for episode in top_3_episodes:\n",
    "    episode_index = episode[0]\n",
    "    similarity_score = episode[1]\n",
    "    print(f\"Episode {episode_index}: Similarity Score = {similarity_score}\")\n",
    "    print(df['エピソード本文'][episode_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改　Sentence BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "比較したいエピソード: Episode 10\n",
      "Episode: 生理期間中によそのお宅を訪問する予定が重なった時、その家のお手洗いを借りた時に生理用品を交換したくても、使用後の生理用品の対処が分かりません。みなさんどのようにされているのでしょうか？よその家に使用後のものを捨てさせてもらうのは恥ずかしいし申し訳なくてできません。かといってバッグに入れて持ち帰るのも、衛生的でない気がして躊躇してしまいます。なるべく、そのお宅に入る前後で交換して、お宅にいる間は交換しなくていいようにしていますが、泊まる予定だと長時間交換しないわけにもいきません。生理と訪問/宿泊が重ならないようにカレンダーとにらめっこをして予定を組みますが、予定外だとどうしようもありません。よそのお宅に行くときに生理が重なった時、他の人がどのようにしているのか知りたいです…！\n",
      "上位3つの類似エピソード\n",
      "Episode 36: Similarity Score = 0.6879069805145264\n",
      "自分自身が違う環境に行ったわけではないのですが，職場の変化で驚いたのは，お手洗いに生理用品が置かれるようになったことです．自分で持ってきているのでそんなに共有の用品は利用しないかな？と思っていましたが，突然始まった時などにすごく助かってます．ただ，自分が高校生だと取りに行くのが恥ずかしくなるので共有スペースよりも個室に置いて欲しいと思うだろうなあと思いました（防犯面とかあるから難しいところですね）．\n",
      "Episode 24: Similarity Score = 0.5941427946090698\n",
      "大学生のころ、友だちの家に遊びに行ったときに急に生理が始まった時、申し訳ないなぁと思ってました。でも友だちが、「いろいろあるよ！どれにする？！使って使って！」とニコニコしながら大きな箱からたくさんの生理用品を出して種類とかについて説明してくれた時は、変に気後れしなくてよくなって、すごくうれしかったなぁと記憶に残ってます。\n",
      "Episode 30: Similarity Score = 0.5914623737335205\n",
      "最近，「生理用品の音が鳴るのがはずかしくて学校で生理用品の交換をためらう子がいる」という内容の記事を見ました．たしかに，「恥ずかしがらなくてもいいよ！」と思う派の自分も，廊下に音が聞こえるようなトイレではそーっとナプキンを開けて使ってたなあと思い出しました．粘着力が必要なので音がなりやすいと思いますが，トイレの場所によっては音が静かなグッズがあるといいなあと思いました．あと，今は月経前症候群のお薬のパッケージがパキパキカサカサ鳴るのがなんだか気恥ずかしくて，人気のない給湯室とかで服薬してるので，もっと気軽に静かに飲めるパッケージになるといいなあと願ってます．\n"
     ]
    }
   ],
   "source": [
    "# 必要なパッケージのインストール\n",
    "# %pip install sentence-transformers pandas\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# モデルのロード\n",
    "model = SentenceTransformer('sonoisa/sentence-bert-base-ja-mean-tokens-v2')\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "df = pd.read_csv('data/logepisode.csv')\n",
    "df['エピソード本文'] = df['エピソード本文'].str.replace('\\r', '').str.replace('\\n', '')\n",
    "\n",
    "# エピソードのベクトル化\n",
    "embeddings = model.encode(df['エピソード本文'].tolist())\n",
    "\n",
    "def get_sim2(s1_index, s2_index):\n",
    "    vec1 = embeddings[s1_index]\n",
    "    vec2 = embeddings[s2_index]\n",
    "    similarity = util.pytorch_cos_sim(vec1, vec2).item()\n",
    "    return similarity\n",
    "\n",
    "x = 10  # 比較したいエピソード番号\n",
    "print(f'比較したいエピソード: Episode {x}')\n",
    "print(f'Episode: {df[\"エピソード本文\"][x]}')\n",
    "print('上位3つの類似エピソード')\n",
    "\n",
    "similarity_scores = []\n",
    "for i in range(len(df['エピソード本文'])):\n",
    "    if i != x:\n",
    "        similarity = get_sim2(x, i)\n",
    "        similarity_scores.append((i, similarity))\n",
    "\n",
    "# 類似度の高い順にソート\n",
    "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 上位3つのエピソードを取得\n",
    "top_3_episodes = similarity_scores[:3]\n",
    "\n",
    "# 上位3つのエピソードを表示\n",
    "for episode in top_3_episodes:\n",
    "    episode_index = episode[0]\n",
    "    similarity_score = episode[1]\n",
    "    print(f\"Episode {episode_index}: Similarity Score = {similarity_score}\")\n",
    "    print(df['エピソード本文'][episode_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
